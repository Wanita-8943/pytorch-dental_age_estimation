{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 classification 결과를 환자 단위, 파트 별 단위로 묶어서 결과 만드는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENV SETTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = '3classes'\n",
    "learning_rate = '5e-5'\n",
    "\n",
    "# true label env\n",
    "true_dataset_root = 'E:/Thesis_research/Database/Medical/Dental_directory_dataset'\n",
    "true_lbl_dir = os.path.join(true_dataset_root, 'ClassificationClass',label_type)\n",
    "\n",
    "# prediction env\n",
    "pred_root = f'E:/Thesis_research/results_materials/Dental/raw_prediction_results/{learning_rate}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICTION SETTING AND VOTING\n",
    "\n",
    "* 각 네트워크 별로 4개의 part에 대한 prediction 중 unique 병록번호에 해당하는 prediction들을 모아서 voting해서 true와 비교!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "part_list = [16, 26, 36, 46]\n",
    "exp_dir = os.path.join(pred_root, label_type)\n",
    "fold_name_list = sorted(os.listdir(exp_dir))\n",
    "\n",
    "## Overall accuracy metric\n",
    "patient_wise_overall_acc_lst = []\n",
    "part_wise_overall_acc_dic = {}\n",
    "for i_part in part_list:\n",
    "    part_wise_overall_acc_dic[i_part] = []\n",
    "\n",
    "## Confusion matrix metric\n",
    "confusion_matrix_metric_tot_lst = []\n",
    "confusion_matrix_metric_partwise_tot_dict = {}\n",
    "for i_part in part_list:\n",
    "    confusion_matrix_metric_partwise_tot_dict[i_part] = []\n",
    "    \n",
    "for i_fold_iter, i_fold_name in enumerate(fold_name_list):\n",
    "    print()\n",
    "    print('Current: ', i_fold_name)\n",
    "    \n",
    "    ## TRUE LABEL SETTING\n",
    "\n",
    "    # * Construct (personnum,true label) pair\n",
    "    true_imageset_path = os.path.join(true_dataset_root,'ImageSets','Classification','eval' + str(i_fold_iter+1) + '.txt')\n",
    "    \n",
    "    with open(true_imageset_path, 'r') as f:\n",
    "         eval_img_list = f.read().split('\\n')\n",
    "\n",
    "    person_num_list =[]\n",
    "    for i_eval_img in eval_img_list:\n",
    "        if i_eval_img == '':\n",
    "            continue\n",
    "        eval_img_info = i_eval_img.split('_')\n",
    "        age_person_num = eval_img_info[0] + '_' + eval_img_info[1] # e.g. '20_2392392' because there are three miss labeled images file name\n",
    "        if len(eval_img_info)>1: # skip blank line\n",
    "            person_num_list.append(age_person_num)\n",
    "    person_num_unique_list, unique_idx = np.unique(np.array(person_num_list), return_index=True)\n",
    "    \n",
    "    pred_by_part = {}\n",
    "    true_by_part = {}\n",
    "    for i_part in part_list:\n",
    "        pred_by_part[i_part] = []\n",
    "        true_by_part[i_part] = []\n",
    "    \n",
    "    person_num_perdiction_all_list = []\n",
    "    true_lbl_unique = []\n",
    "    \n",
    "    for i_iter, i_person_num_unique in enumerate(person_num_unique_list):\n",
    "        pred_dir = os.path.join(exp_dir, i_fold_name, 'eval_result_resnet152_cls_best_model', 'prediction_class')\n",
    "        pred_result_list = sorted(os.listdir(pred_dir))\n",
    "        pred_result_person_num = [s for s in pred_result_list if i_person_num_unique in s]\n",
    "        \n",
    "        # 하나라도 파트 없으면 false alarm!!\n",
    "        if not len(pred_result_person_num) == 4 :\n",
    "            print('Each person must have four teeth parts')\n",
    "            raise AssertionError\n",
    "            \n",
    "        # true label setting\n",
    "        true_lbl = 0\n",
    "        for i, i_pred in enumerate(pred_result_person_num):\n",
    "            true_lbl_path = os.path.join(true_lbl_dir, i_pred)\n",
    "            with open(true_lbl_path,'r') as f:\n",
    "                lbl = int(f.read())\n",
    "            if i==0:\n",
    "                true_lbl = lbl\n",
    "            else:\n",
    "                if true_lbl != lbl: # check all patients label is the same each other\n",
    "                    raise AssertionError\n",
    "                else:\n",
    "                    true_lbl = lbl\n",
    "        true_lbl_unique.append(true_lbl)\n",
    "            \n",
    "        person_num_prediction = []\n",
    "        for i_pred in pred_result_person_num:\n",
    "            pred_txt_nameOnly = os.path.splitext(i_pred)[0]\n",
    "            pred_name_info = pred_txt_nameOnly.split('_')\n",
    "            part_num = int(pred_name_info[-1])\n",
    "            pred_result_path = os.path.join(pred_dir, i_pred)\n",
    "            with open(pred_result_path, 'r') as f:\n",
    "                pred_lbl = int(f.read())\n",
    "            person_num_prediction.append(pred_lbl)\n",
    "            pred_by_part[part_num].append(pred_lbl)\n",
    "            true_by_part[part_num].append(true_lbl)\n",
    "            \n",
    "            \n",
    "        person_num_perdiction_all_list.append(person_num_prediction)\n",
    "    \n",
    "    network_final_pred_list = []\n",
    "    for i_person_num_pred in person_num_perdiction_all_list:\n",
    "        most_common_pred, num_most_common_pred = Counter(i_person_num_pred).most_common(1)[0] # 4, 6 times\n",
    "        network_final_pred_list.append(most_common_pred)\n",
    "    \n",
    "    confusion_matrix_metric = confusion_matrix(true_lbl_unique, network_final_pred_list)\n",
    "    print('Confusion matrix: ')\n",
    "    print(confusion_matrix_metric)\n",
    "    confusion_matrix_metric_tot_lst.append(confusion_matrix_metric)\n",
    "    \n",
    "    overall_acc_metric = accuracy_score(true_lbl_unique, network_final_pred_list)\n",
    "    print('Overall accuracy = ', overall_acc_metric)\n",
    "    \n",
    "    patient_wise_overall_acc_lst.append(overall_acc_metric)\n",
    "    \n",
    "    \n",
    "    ## save as excel\n",
    "    index =['True'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "    columns = ['Pred'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "    df_total = pandas.DataFrame(confusion_matrix_metric, index=index, columns = columns)\n",
    "    save_excel_path = os.path.join(exp_dir, i_fold_name, 'conf_mat_total.xlsx')\n",
    "    df_total.to_excel(save_excel_path)\n",
    "    \n",
    "    \n",
    "    print('======== part by part metric ==========')\n",
    "    for key in pred_by_part:\n",
    "        print('PART NUM: ', key)\n",
    "        confusion_matrix_metric = confusion_matrix(true_by_part[key], pred_by_part[key])\n",
    "        confusion_matrix_metric_partwise_tot_dict[key].append(confusion_matrix_metric) \n",
    "        print('Confusion matrix: ')\n",
    "        print(confusion_matrix_metric)\n",
    "        overall_acc_metric = accuracy_score(true_by_part[key], pred_by_part[key])\n",
    "        print('Overall accuracy = ', overall_acc_metric)\n",
    "        part_wise_overall_acc_dic[key].append(overall_acc_metric)\n",
    "        \n",
    "        index =['True'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "        columns = ['Pred'+str(i) for i in range(1, confusion_matrix_metric.shape[0]+1)]\n",
    "        df_part = pandas.DataFrame(confusion_matrix_metric, index=index, columns = columns)\n",
    "        save_excel_path = os.path.join(exp_dir, i_fold_name, 'conf_mat_part' + str(key) +'.xlsx')\n",
    "        df_total.to_excel(save_excel_path)\n",
    "\n",
    "confmat_save_path = os.path.join(exp_dir, '3cls_conf_mat_tot.npy')\n",
    "np.save(confmat_save_path, confusion_matrix_metric_tot_lst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient wise cv 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix: ')\n",
    "confusion_matrix_metric_tot = np.array(confusion_matrix_metric_tot_lst)\n",
    "confusion_matrix_metric_avg = np.mean(confusion_matrix_metric_tot, axis = 0)\n",
    "print(confusion_matrix_metric_avg)\n",
    "print()\n",
    "print('Overall Accuracy: ')\n",
    "patient_wise_avg_acc = np.mean(patient_wise_overall_acc_lst)\n",
    "patient_wise_std_error= np.std(patient_wise_overall_acc_lst) / np.sqrt(len(patient_wise_overall_acc_lst))\n",
    "print('acc: ',patient_wise_avg_acc)\n",
    "print('std_error: ', patient_wise_std_error)\n",
    "print()\n",
    "print('Group-wise accuracy: ')\n",
    "group_wise_acc_dict={}\n",
    "for i_group in range(confusion_matrix_metric_tot.shape[1]):\n",
    "    group_wise_acc_dict[i_group] = []\n",
    "    for i_fold in range(confusion_matrix_metric_tot.shape[0]):\n",
    "        confusion_matrix_cur = confusion_matrix_metric_tot[i_fold]\n",
    "        group_wise_acc = confusion_matrix_cur[i_group, i_group] / np.sum(confusion_matrix_cur[i_group, :])\n",
    "        group_wise_acc_dict[i_group].append(group_wise_acc)\n",
    "        \n",
    "    group_wise_acc_mean = np.mean(group_wise_acc_dict[i_group])\n",
    "    group_wise_acc_std_error = np.std(group_wise_acc_dict[i_group]) / np.sqrt(len(group_wise_acc_dict[i_group]))\n",
    "    print('Age group ' + str(i_group+1))\n",
    "    print('acc: ',group_wise_acc_mean)\n",
    "    print('std_error: ',group_wise_acc_std_error)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(confusion_matrix_metric_tot_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part wise cv 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i_part in part_list:\n",
    "    print('===============')\n",
    "    print('Part', i_part)\n",
    "\n",
    "    print('Confusion matrix: ')\n",
    "    confusion_matrix_metric_tot = np.array(confusion_matrix_metric_partwise_tot_dict[i_part])\n",
    "    confusion_matrix_metric_avg = np.mean(confusion_matrix_metric_tot, axis = 0)\n",
    "    print(confusion_matrix_metric_avg)\n",
    "    print()\n",
    "    print('Overall Accuracy: ')\n",
    "    part_wise_avg_acc = np.mean(part_wise_overall_acc_dic[i_part])\n",
    "    part_wise_std_error= np.std(part_wise_overall_acc_dic[i_part]) / np.sqrt(len(part_wise_overall_acc_dic[i_part]))\n",
    "    print('acc: ', part_wise_avg_acc)\n",
    "    print('std_error: ', part_wise_std_error)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient-wise, part-wise 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==== Patient-wise overall acc ====')\n",
    "patient_wise_avg_acc = np.mean(patient_wise_overall_acc_lst)\n",
    "patient_wise_std_error= np.std(patient_wise_overall_acc_lst) / np.sqrt(len(patient_wise_overall_acc_lst))\n",
    "print('avg: ',patient_wise_avg_acc * 100)\n",
    "print('std_error: ', patient_wise_std_error*100)\n",
    "\n",
    "print('==== Part-wise overall acc ====')\n",
    "for i_part in part_list:\n",
    "    print('Part', i_part)\n",
    "    part_wise_avg_acc = np.mean(part_wise_overall_acc_dic[i_part])\n",
    "    part_wise_std_error= np.std(part_wise_overall_acc_dic[i_part]) / np.sqrt(len(part_wise_overall_acc_dic[i_part]))\n",
    "    print('avg: ', part_wise_avg_acc*100)\n",
    "    print('std_error: ', part_wise_std_error*100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save data for using at t-test in 3cls+5cls voting\n",
    "np.save(os.path.join(exp_dir, '3cls_patient_wise_acc_lst.npy'), patient_wise_overall_acc_lst)\n",
    "for i_part in part_list:\n",
    "    out_file_name = os.path.join(exp_dir, '3cls_part'+str(i_part)+'_acc_lst.npy')\n",
    "    np.save(out_file_name, part_wise_overall_acc_dic[i_part])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "for i_part in part_list:\n",
    "    print('Patient-wise acc vs part ' + str(i_part) + ' acc')\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_overall_acc_dic[i_part])\n",
    "    print(\"p-value\", pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "for i_part in part_list:\n",
    "    print('Patient-wise acc vs part ' + str(i_part) + ' acc')\n",
    "    ttest,pval = ttest_ind(patient_wise_overall_acc_lst,part_wise_overall_acc_dic[i_part], equal_var=False)\n",
    "    print(\"p-value\",pval)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
